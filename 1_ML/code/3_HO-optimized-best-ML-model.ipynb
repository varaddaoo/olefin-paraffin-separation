{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#mpl.rc('figure', max_open_warning = 0)\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class style:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() # Getting current directory\n",
    "descriptor_in_path = os.path.join(PATH, '../input/descriptor.csv')\n",
    "\n",
    "df_descriptor = pd.read_csv(descriptor_in_path)\n",
    "\n",
    "print(f'Descriptor input DataFrame shape:\\n\\n {df_descriptor.shape}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print(f'\\nDescriptor input data columns:\\n\\n {df_descriptor.columns}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print(f'\\nDescriptor input dataframe head:\\n\\n {df_descriptor.head()}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "del descriptor_in_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f2bea",
   "metadata": {},
   "source": [
    "## Renaming descriptor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'name': 'mof', 'Di': 'LCD', 'Df': 'PLD', 'ASA(m2/gram)_1.9': 'GSA', \n",
    "               'AV_Volume_fraction_1.9': 'AVF', 'AV(cm3/gram)_1.9': 'GPV', 'density(gram_cm3)': 'Density'}\n",
    "\n",
    "df_descriptor = df_descriptor.rename(columns=rename_dict)\n",
    "\n",
    "print(f'\\nCurated descriptor columns:\\n\\n {df_descriptor.columns}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print(df_descriptor.dtypes) # Prints the datatype of each column in dataframe\n",
    "del rename_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5abbda",
   "metadata": {},
   "source": [
    "## Curating descriptor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptor_gross1_atomic = df_descriptor\n",
    "\n",
    "# Selecting materials with PLD > 3.8 A\n",
    "\n",
    "df_descriptor_gross1_atomic = df_descriptor_gross1_atomic[(df_descriptor_gross1_atomic['PLD'] > 3.8)]\n",
    "\n",
    "# Selecting materials with non-zero void fraction\n",
    "\n",
    "df_descriptor_gross1_atomic = df_descriptor_gross1_atomic[(df_descriptor_gross1_atomic['AVF'] > 0.0)]\n",
    "\n",
    "descriptor_mof_name = df_descriptor_gross1_atomic['mof'].astype(str)\n",
    "\n",
    "PATH = os.getcwd() # Getting current directory\n",
    "curated_mof_name = os.path.join(PATH, '../output/curated-mof.csv')\n",
    "descriptor_mof_name.to_csv(curated_mof_name, index=False)\n",
    "\n",
    "columns = ['PLD', 'LCD', 'GSA', 'AVF', 'GPV', 'Density', 'total_degree_unsaturation', 'degree_unsaturation', \n",
    "           'metallic_percentage', 'O_to_Metal_ration', 'N_to_O_ratio', 'H' ,'Ni', 'Co', 'Cu', 'Zn', 'Pb', 'Mn',\n",
    "           'Cd', 'C', 'O', 'N', 'S', 'Cl', 'Br', 'F', 'I']\n",
    "\n",
    "shap_columns = columns\n",
    "\n",
    "df_descriptor_gross1_atomic = df_descriptor_gross1_atomic[columns].astype(float)\n",
    "curated_mof_prop = os.path.join(PATH, '../output/curated-mof-prop.csv')\n",
    "\n",
    "df_descriptor_gross1_atomic.to_csv(curated_mof_prop, index=False)\n",
    "\n",
    "print(f'\\nCurated gross1_atomic descriptor data:\\n\\n {df_descriptor_gross1_atomic}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "print(f'\\nData type of each column. Note that it should be float\\n\\n {df_descriptor_gross1_atomic.dtypes}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "del df_descriptor\n",
    "del columns\n",
    "del descriptor_mof_name\n",
    "del curated_mof_name\n",
    "del curated_mof_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae88ece",
   "metadata": {},
   "source": [
    "## Taking look at target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_in_path = os.path.join(PATH, '../input/C3H8-C3H6.csv')\n",
    "#target_in_path = os.path.join(PATH, '../input/C2H6-C2H4.csv')\n",
    "\n",
    "df_target = pd.read_csv(target_in_path)\n",
    "\n",
    "print(f'Target property input DataFrame shape:\\n\\n {df_target.shape}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print(f'\\nTarget property input data columns:\\n\\n {df_target.columns}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print(f'\\nTarget property input dataframe head:\\n\\n {df_target.head()}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "del target_in_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2582f91",
   "metadata": {},
   "source": [
    "## Renaming Target property columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'MOF_no': 'mof', 'propane_avg(mol/kg)': 'propane_uptake(mol/kg)',\n",
    "              'propylene_avg(mol/kg)': 'propylene_uptake(mol/kg)',\n",
    "              'C3H8/C3H6 Selectivity (1Bar)': 'propane_propylene_selectivity', 'Df': 'PLD',\n",
    "              'AV_Volume_fraction_1.9': 'AVF'}\n",
    "'''\n",
    "\n",
    "rename_dict = {'MOF_no': 'mof', 'ethane_avg(mol/kg)': 'ethane_uptake(mol/kg)',\n",
    "              'ethylene_avg(mol/kg)': 'ethylene_uptake(mol/kg)',\n",
    "              'C2H6/C2H4 Selectivity (1Bar)': 'ethane_ethylene_selectivity', 'Df': 'PLD',\n",
    "              'AV_Volume_fraction_1.9': 'AVF'}\n",
    "\n",
    "'''\n",
    "df_target = df_target.rename(columns=rename_dict)\n",
    "\n",
    "print(f'\\nCurated target columns:\\n\\n {df_target.columns}\\n')\n",
    "print('------------------------------------------------------------')\n",
    "      \n",
    "del rename_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfe5ff",
   "metadata": {},
   "source": [
    "## Curating Target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_gross1_atomic = df_target\n",
    "\n",
    "# Selecting materials with PLD > 3.8 A\n",
    "\n",
    "df_target_gross1_atomic = df_target_gross1_atomic[(df_target_gross1_atomic['PLD'] > 3.8)]\n",
    "\n",
    "# Selecting material with AVF > 0\n",
    "df_target_gross1_atomic = df_target_gross1_atomic[(df_target_gross1_atomic['AVF'] > 0.0)]\n",
    "\n",
    "target_mof_name = df_target_gross1_atomic['mof'].astype(str)\n",
    "target_mof_name_path = os.path.join(PATH, '../output/target-mof-name.csv')\n",
    "target_mof_name.to_csv(target_mof_name_path, index=False)\n",
    "\n",
    "columns = ['propane_uptake(mol/kg)', 'propane_propylene_selectivity', 'TSN', 'propylene_uptake(mol/kg)']\n",
    "\n",
    "#columns = ['ethane_uptake(mol/kg)', 'ethane_ethylene_selectivity', 'TSN', 'ethylene_uptake(mol/kg)']\n",
    "\n",
    "\n",
    "df_target_gross1_atomic = df_target_gross1_atomic[columns].astype(float)\n",
    "target_mof_prop_path = os.path.join(PATH, '../output/target-mof-prop.csv')\n",
    "\n",
    "print(f'\\nCurated target data:\\n\\n {df_target_gross1_atomic}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "print(f'\\nData type of each column. Note that it should be float\\n\\n {df_target_gross1_atomic.dtypes}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "del df_target\n",
    "del columns\n",
    "del target_mof_name\n",
    "del target_mof_name_path\n",
    "del target_mof_prop_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "profile = ProfileReport(df_join.copy(),title='C3H8-C3H6', html={'style':{'full_width':True}})\n",
    "# profile.to_widgets()\n",
    "#profile.to_notebook_iframe()\n",
    "C3H8_report = os.path.join(PATH, '../output/C3H8-C3H6-report.csv')\n",
    "\n",
    "profile.to_file(\"/home/varad/Pictures/best_model_selection_updated/1_excluding_oms/1_Propane_RACs_excluding.html\")\n",
    "\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crude = df_descriptor_gross1_atomic\n",
    "Y_crude = df_target_gross1_atomic\n",
    "\n",
    "print(f'\\nShape of X_crude: {X_crude.shape}')\n",
    "print(f'\\nShape of Y_crude: {Y_crude.shape}')\n",
    "\n",
    "del df_descriptor_gross1_atomic\n",
    "del df_target_gross1_atomic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4ca01",
   "metadata": {},
   "source": [
    "# Creating validation set and using the same validation set for all the random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_val_crude, Y, Y_val_crude = train_test_split(X_crude, Y_crude, test_size=0.32, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_crude)\n",
    "X_val_scaled   = scaler.transform(X_val_crude)\n",
    "X_test_scaled  = scaler.transform(X_test_crude)\n",
    "\n",
    "# Normalizing the unscaled data\n",
    "norm = MinMaxScaler().fit(X_train_crude)\n",
    "\n",
    "X_train_norm  = norm.transform(X_train_crude)\n",
    "X_val_norm    = norm.transform(X_val_crude)\n",
    "X_test_norm   = norm.transform(X_test_crude)\n",
    "\n",
    "# Normalizing the scaled data\n",
    "norm_scaled         = MinMaxScaler().fit(X_train_scaled)\n",
    "\n",
    "X_train_scaled_norm = norm_scaled.transform(X_train_scaled)\n",
    "X_val_scaled_norm   = norm_scaled.transform(X_val_scaled)\n",
    "X_test_scaled_norm  = norm_scaled.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment when model has to be trained on crude data\n",
    "\n",
    "#X_train = X_train_crude\n",
    "#X_val   = X_val_crude\n",
    "#X_test  = X_test_crude\n",
    "\n",
    "## Uncomment when model has to be trained on scaled data\n",
    "\n",
    "#X_train = X_train_scaled\n",
    "#X_val   = X_val_scaled\n",
    "#X_test  = X_test_scaled\n",
    "\n",
    "## Uncomment when model has to be trained on normalised data\n",
    "#X_train = X_train_norm\n",
    "#X_val   = X_val_norm\n",
    "#X_test  = X_test_norm\n",
    "\n",
    "## Uncomment when model has to be trained on scaled_normalised  data\n",
    "X_train  = X_train_scaled_norm\n",
    "X_val    = X_val_scaled_norm\n",
    "X_test   = X_test_scaled_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Y is neigther scaled nor normalized\n",
    "\n",
    "# If index is 0 then, propane / ethane uptake (mol/kg)  \n",
    "# If index is 1 then, selectivity\n",
    "# If index is 2 then, TSN\n",
    "# If index is 3 then, propylene / ethylene uptake (mol/kg)\n",
    "\n",
    "print('------------------------------------------------------------')\n",
    "print(style.BOLD + 'Define property here :' + style.END)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "Y_target_train = Y_train_crude.iloc[:,1]\n",
    "Y_target_test  = Y_test_crude.iloc[:,1]\n",
    "Y_target_val   = Y_val_crude.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Propane + Selectivity + atomic + excluding + scaled + normalized) + GBR\n",
    "\n",
    "X_train = X_train[:,[3,2,0,21,1,11,7,13,12,17]]\n",
    "X_test  = X_test[:,[3,2,0,21,1,11,7,13,12,17]]\n",
    "X_val   = X_val[:,[3,2,0,21,1,11,7,13,12,17]]\n",
    "\n",
    "shap_columns = X_crude.columns[[3,2,0,21,1,11,7,13,12,17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4ef1e",
   "metadata": {},
   "source": [
    "## Grid search for Propane selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "             'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be299466",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "\n",
    "grid_search.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = grid_search.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ticks = [1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1]\n",
    "plt.axes().set_xticks(ticks)\n",
    "plt.axes().set_yticks(ticks)\n",
    "\n",
    "#[1.75, 1.32, 1.7, 1.27, 1.665, 1.24, 1.65, 1.21]\n",
    "plt.text(1.75, 1.32, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.7, 1.27, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.665, 1.23, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) +  \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.645, 1.19, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) +  \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c912b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d884a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f7076",
   "metadata": {},
   "source": [
    "## Shap analysis on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=RNG_SEED, bootstrap = 'False', max_depth = 10,\n",
    "                            max_features = 'sqrt', n_estimators = 50, min_samples_split = 2,\n",
    "                            min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23549cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = rfr.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = rfr.predict(X_train)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ticks = [1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1]\n",
    "plt.axes().set_xticks(ticks)\n",
    "plt.axes().set_yticks(ticks)\n",
    "\n",
    "plt.text(1.75, 1.32, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.7, 1.27, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.665, 1.23, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.645, 1.19, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bade42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rfr)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, feature_names = shap_columns, max_display = 15, show = False)\n",
    "plt.title(\"Feature importance calculated using SHAP for propane-propylene selectivity for train set\\n\", fontweight = \"bold\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2999f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rfr\n",
    "del grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5db20",
   "metadata": {},
   "source": [
    "## Combining training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f14eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis=0)\n",
    "Y_train_new = pd.concat((Y_target_train, Y_target_val), axis=0)\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(Y_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6843908d",
   "metadata": {},
   "source": [
    "## Retraining model on combined train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a20f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa86d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a46120",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "             'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd74639",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "\n",
    "grid_search.fit(X_train_new, Y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae56284",
   "metadata": {},
   "source": [
    "## Grid search results\n",
    "\n",
    "Print out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc417d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_selectivity = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cv_result_selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results of all the hyperparameters searched\n",
    "\n",
    "#df_cv_result_selectivity = df_cv_result_selectivity.astype(float)\n",
    "#df_cv_result_selectivity.to_csv('/home/varad/varad/literature/24_sauradeep/workspace/ML/output/2_Gross1_Atomic/grid_search_results/selectivity/1_selectivity_propane_propylene_grid_search_results_excluding_oms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_selectivity.columns\n",
    "\n",
    "print(f'\\nGrid search results:\\n\\n {df_cv_result_selectivity}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ca773",
   "metadata": {},
   "source": [
    "## Printing out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa175f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = grid_search.cv_results_['mean_test_score']\n",
    "std_test = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "std_train = grid_search.cv_results_['std_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_test = grid_search.predict(X_test) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train_new)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "a = Y_train_new\n",
    "b = Y_target_test\n",
    "\n",
    "plt.scatter(Y_target_test, Y_pred_test, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_train_new, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_test),np.max(Y_target_test)], \n",
    "         [np.min(Y_target_test),np.max(Y_target_test)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and test set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ticks = [1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1]\n",
    "plt.axes().set_xticks(ticks)\n",
    "plt.axes().set_yticks(ticks)\n",
    "\n",
    "#[1.75, 1.32, 1.7, 1.27, 1.665, 1.24, 1.65, 1.21]\n",
    "\n",
    "plt.text(1.75, 1.32, str('Train     Test'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.7, 1.27, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_train_new, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.665, 1.23, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_train_new, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(1.645, 1.19, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_train_new, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8557fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_selectivity = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rfr\n",
    "del RandomForestRegressor\n",
    "del param_grid\n",
    "del grid_search\n",
    "del GridSearchCV\n",
    "del ticks\n",
    "#del mean_val\n",
    "del mean_train\n",
    "#del std_val\n",
    "#del std_train\n",
    "del Y_pred_val\n",
    "del Y_pred_train\n",
    "del localimportance\n",
    "del explainer\n",
    "del index\n",
    "del feature_importance\n",
    "del df_cv_result_selectivity\n",
    "del shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648a81f",
   "metadata": {},
   "source": [
    "## Grid search for Propane uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment when model has to be trained on crude data\n",
    "\n",
    "#X_train = X_train_crude\n",
    "#X_val   = X_val_crude\n",
    "#X_test  = X_test_crude\n",
    "\n",
    "## Uncomment when model has to be trained on scaled data\n",
    "\n",
    "#X_train = X_train_scaled\n",
    "#X_val   = X_val_scaled\n",
    "#X_test  = X_test_scaled\n",
    "\n",
    "## Uncomment when model has to be trained on normalised data\n",
    "#X_train = X_train_norm\n",
    "#X_val   = X_val_norm\n",
    "#X_test  = X_test_norm\n",
    "\n",
    "## Uncomment when model has to be trained on scaled_normalised  data\n",
    "X_train  = X_train_scaled_norm\n",
    "X_val    = X_val_scaled_norm\n",
    "X_test   = X_test_scaled_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aafc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Y is neigther scaled nor normalized\n",
    "\n",
    "# If index is 0 then, propane / ethane uptake (mol/kg)  \n",
    "# If index is 1 then, selectivity\n",
    "# If index is 2 then, TSN\n",
    "# If index is 3 then, propylene / ethylene uptake (mol/kg)\n",
    "\n",
    "Y_target_train = Y_train_crude.iloc[:,0]\n",
    "Y_target_test  = Y_test_crude.iloc[:,0]\n",
    "Y_target_val   = Y_val_crude.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Propane + propane_uptake + atomic + excluding + scaled + normalized) + GBR\n",
    "\n",
    "X_train = X_train[:,[0,2,7,11,15,1,6,25,3,4,12]]\n",
    "X_test  = X_test[:,[0,2,7,11,15,1,6,25,3,4,12]]\n",
    "X_val   = X_val[:,[0,2,7,11,15,1,6,25,3,4,12]]\n",
    "\n",
    "shap_columns = X_crude.columns[[0,2,7,11,15,1,6,25,3,4,12]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44422d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=RNG_SEED)\n",
    "#svr = SVR() # random_state=RNG_SEED cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73358f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "\n",
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "              'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "'''\n",
    "# svr\n",
    "param_grid = {'kernel':['rbf', 'sigmoid', 'poly', 'linear'], 'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], 'epsilon': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              'degree': [1,2,3,4,5,6]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "\n",
    "grid_search = GridSearchCV(estimator = etr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "\n",
    "'''\n",
    "# svr\n",
    "grid_search = GridSearchCV(estimator = svr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "\n",
    "'''\n",
    "grid_search.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e227ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = grid_search.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#0.8, 0.3, 0.75, 0.25, 0.7, 0.20, 0.68, 0.15\n",
    "plt.text(0.8, 0.3, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.74, 0.25, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.7, 0.20, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.68, 0.15, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62160f3",
   "metadata": {},
   "source": [
    "## Shap analysis on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ce958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "etr = ExtraTreesRegressor(random_state=RNG_SEED, bootstrap = 'False', max_depth = 20,\n",
    "                            max_features = 'auto', n_estimators = 50, min_samples_split = 2,\n",
    "                            min_samples_leaf = 1)\n",
    "\n",
    "\n",
    "#svr = SVR(C = 10.0, degree = 1, epsilon = 0.01, gamma = 1.0, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = etr.fit(X_train, Y_target_train)\n",
    "#model = svr.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = etr.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = etr.predict(X_train)\n",
    "'''\n",
    "Y_pred_val = svr.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = svr.predict(X_train)\n",
    "\n",
    "'''\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $S_{C_{3}H_{8}/C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#0.8, 0.3, 0.75, 0.25, 0.7, 0.20, 0.68, 0.15\n",
    "plt.text(0.8, 0.3, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.74, 0.25, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.7, 0.20, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.68, 0.15, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad05cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del shap\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(etr)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, feature_names = shap_columns, max_display = 15, show = False)\n",
    "plt.title(\"Feature importance calculated using SHAP for Propane-Uptake (mol/kg) for train set\\n\", fontweight = \"bold\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06b028",
   "metadata": {},
   "source": [
    "## Combining training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis=0)\n",
    "Y_train_new = pd.concat((Y_target_train, Y_target_val), axis=0)\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(Y_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368650f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr\n",
    "del grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecd68e",
   "metadata": {},
   "source": [
    "## Retraining model on combined train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=RNG_SEED)\n",
    "#svr = SVR() # random_state=RNG_SEED cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274beec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "\n",
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "              'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "'''\n",
    "# svr\n",
    "param_grid = {'kernel':['rbf', 'sigmoid', 'poly', 'linear'], 'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], 'epsilon': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              'degree': [1,2,3,4,5,6]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search = GridSearchCV(estimator = etr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "'''\n",
    "grid_search = GridSearchCV(estimator = svr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "'''\n",
    "grid_search.fit(X_train_new, Y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9c756",
   "metadata": {},
   "source": [
    "## Grid search results\n",
    "\n",
    "Print out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_propane_uptake = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cv_result_propane_uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results of all the hyperparameters searched\n",
    "\n",
    "#df_cv_result_propane_uptake = df_cv_result_propane_uptake.astype(float)\n",
    "#df_cv_result_propane_uptake.to_csv('/home/varad/varad/literature/24_sauradeep/workspace/ML/output/2_Gross1_Atomic/grid_search_results/selectivity/1_selectivity_propane_propylene_grid_search_results_excluding_oms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc098fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_propane_uptake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(f'\\nGrid search results:\\n\\n {df_cv_result_selectivity}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775cdab",
   "metadata": {},
   "source": [
    "## Printing out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eab12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = grid_search.cv_results_['mean_test_score']\n",
    "std_test = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "std_train = grid_search.cv_results_['std_train_score']\n",
    "\n",
    "'''\n",
    "for mean, std, params in zip(-means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27075679",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_test = grid_search.predict(X_test) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train_new)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_test, Y_pred_test, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_train_new, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_test),np.max(Y_target_test)], \n",
    "         [np.min(Y_target_test),np.max(Y_target_test)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and test set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $N_{C_{3}H_{8}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $N_{C_{3}H_{8}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# 0.8, 0.3, 0.75, 0.25, 0.7, 0.20, 0.68, 0.15\n",
    "\n",
    "plt.text(0.8, 0.3, str('Train     Test'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.74, 0.25, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_train_new, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.7, 0.20, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_train_new, Y_pred_train)) +\n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.68, 0.15, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_train_new, Y_pred_train)) +\n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11215295",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_propane_uptake = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3102ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr\n",
    "del param_grid\n",
    "del grid_search\n",
    "del GridSearchCV\n",
    "#del ticks\n",
    "#del mean_val\n",
    "del mean_train\n",
    "#del std_val\n",
    "#del std_train\n",
    "del Y_pred_val\n",
    "del Y_pred_train\n",
    "del localimportance\n",
    "del explainer\n",
    "del index\n",
    "del feature_importance\n",
    "del df_cv_result_propane_uptake\n",
    "del shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48080633",
   "metadata": {},
   "source": [
    "## Grid search for Propylene uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment when model has to be trained on crude data\n",
    "\n",
    "#X_train = X_train_crude\n",
    "#X_val   = X_val_crude\n",
    "#X_test  = X_test_crude\n",
    "\n",
    "## Uncomment when model has to be trained on scaled data\n",
    "\n",
    "#X_train = X_train_scaled\n",
    "#X_val   = X_val_scaled\n",
    "#X_test  = X_test_scaled\n",
    "\n",
    "## Uncomment when model has to be trained on normalised data\n",
    "#X_train = X_train_norm\n",
    "#X_val   = X_val_norm\n",
    "#X_test  = X_test_norm\n",
    "\n",
    "## Uncomment when model has to be trained on scaled_normalised  data\n",
    "X_train  = X_train_scaled_norm\n",
    "X_val    = X_val_scaled_norm\n",
    "X_test   = X_test_scaled_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb89fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Y is neigther scaled nor normalized\n",
    "\n",
    "# If index is 0 then, propane / ethane uptake (mol/kg)  \n",
    "# If index is 1 then, selectivity\n",
    "# If index is 2 then, TSN\n",
    "# If index is 3 then, propylene / ethylene uptake (mol/kg)\n",
    "\n",
    "Y_target_train = Y_train_crude.iloc[:,3]\n",
    "Y_target_test  = Y_test_crude.iloc[:,3]\n",
    "Y_target_val   = Y_val_crude.iloc[:,3]\n",
    "\n",
    "temp_train = Y_train_crude.iloc[:,1]\n",
    "temp_test  = Y_test_crude.iloc[:,1]\n",
    "temp_val   = Y_val_crude.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Propane + propylene_uptake + atomic + excluding + scaled + normalized) + GBR\n",
    "\n",
    "X_train = X_train[:,[2,7,11,15,1,5,6,3,22,4,21,25,16]]\n",
    "X_test  = X_test[:,[2,7,11,15,1,5,6,3,22,4,21,25,16]]\n",
    "X_val   = X_val[:,[2,7,11,15,1,5,6,3,22,4,21,25,16]]\n",
    "\n",
    "shap_columns = X_crude.columns[[2,7,11,15,1,5,6,3,22,4,21,25,16]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e304a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=RNG_SEED)\n",
    "#svr = SVR() # random_state=RNG_SEED cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "\n",
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "              'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "'''\n",
    "# svr\n",
    "param_grid = {'kernel':['rbf', 'sigmoid', 'poly', 'linear'], 'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], 'epsilon': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              'degree': [1,2,3,4,5,6]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742afa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "# change\n",
    "grid_search = GridSearchCV(estimator = etr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "\n",
    "'''\n",
    "# svr\n",
    "grid_search = GridSearchCV(estimator = svr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "'''\n",
    "\n",
    "grid_search.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c189bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc920c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = grid_search.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $N_{C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $N_{C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#3.0, 1.3, 2.7, 1.1, 2.5, 0.9, 2.41, 0.7\n",
    "plt.text(3.0, 1.3, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.74, 0.25, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.7, 1.1, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.41, 0.7, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c9237",
   "metadata": {},
   "source": [
    "## Shap analysis on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69623d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd863025",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=RNG_SEED, bootstrap = 'False', max_depth = 20,\n",
    "                            max_features = 'auto', n_estimators = 250, min_samples_split = 4,\n",
    "                            min_samples_leaf = 1)\n",
    "\n",
    "\n",
    "#svr = SVR(C = 100.0, degree = 1, epsilon = 0.1, gamma = 1.0, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff102bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = etr.fit(X_train, Y_target_train)\n",
    "#model = svr.fit(X_train, Y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e01c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_val = etr.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = etr.predict(X_train)\n",
    "'''\n",
    "Y_pred_val = svr.predict(X_val) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = svr.predict(X_train)\n",
    "'''\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_val, Y_pred_val, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_target_train, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_val),np.max(Y_target_val)], \n",
    "         [np.min(Y_target_val),np.max(Y_target_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and validation set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $N_{C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $N_{C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#3.0, 1.3, 2.7, 1.1, 2.5, 0.9, 2.41, 0.7\n",
    "plt.text(3.0, 1.3, str('Train     Val'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(0.74, 0.25, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.5, 0.9, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.41, 0.7, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_target_train, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_val, Y_pred_val)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ec408",
   "metadata": {},
   "outputs": [],
   "source": [
    "del shap\n",
    "\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(etr)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, feature_names = shap_columns, max_display = 15, show = False)\n",
    "plt.title(\"Feature importance calculated using SHAP for propylene-Uptake (mol/kg) for train set\\n\", fontweight = \"bold\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dade1c",
   "metadata": {},
   "source": [
    "## Combining training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis=0)\n",
    "Y_train_new = pd.concat((Y_target_train, Y_target_val), axis=0)\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(Y_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43328db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_val_comb # selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr\n",
    "del grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab97777",
   "metadata": {},
   "source": [
    "## Retraining model on combined train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5648937",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=RNG_SEED)\n",
    "#svr = SVR() # random_state=RNG_SEED cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etr\n",
    "\n",
    "param_grid = {  'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 150, 500],\n",
    "              'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "'''\n",
    "# svr\n",
    "param_grid = {'kernel':['rbf', 'sigmoid', 'poly', 'linear'], 'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], 'epsilon': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              'degree': [1,2,3,4,5,6]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search = GridSearchCV(estimator = etr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "'''\n",
    "grid_search = GridSearchCV(estimator = svr, param_grid = param_grid, cv = 10,\n",
    "                           scoring = 'neg_mean_absolute_error', return_train_score = True, n_jobs = -1,\n",
    "                          verbose=1000)\n",
    "'''\n",
    "grid_search.fit(X_train_new, Y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e0894",
   "metadata": {},
   "source": [
    "## Grid search results\n",
    "\n",
    "Print out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_propylene_uptake = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cv_result_propylene_uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results of all the hyperparameters searched\n",
    "\n",
    "#df_cv_result_propylene_uptake = df_cv_result_propane_uptake.astype(float)\n",
    "#df_cv_result_propylene_uptake.to_csv('/home/varad/varad/literature/24_sauradeep/workspace/ML/output/2_Gross1_Atomic/grid_search_results/selectivity/1_selectivity_propane_propylene_grid_search_results_excluding_oms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_result_propylene_uptake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d81135",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(f'\\nGrid search results:\\n\\n {df_cv_result_selectivity}\\n')\n",
    "print('\\n------------------------------------------------------------\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4aad39",
   "metadata": {},
   "source": [
    "## Printing out the average validation errors and corresponding hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = grid_search.cv_results_['mean_test_score']\n",
    "std_test = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "std_train = grid_search.cv_results_['std_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab996b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best combinations of parameters are %s with a score of %0.3f on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cca823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted Propane selectivity for all the structures\n",
    "\n",
    "Y_pred_test = grid_search.predict(X_test) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "Y_pred_train = grid_search.predict(X_train_new)\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fontdict_t = {'fontsize': 14, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_x = {'fontsize': 12, 'weight': 'bold', 'ha': 'center'}\n",
    "fontdict_y = {'fontsize': 12, 'weight': 'bold', 'va': 'baseline', 'ha': 'center'}\n",
    "\n",
    "plt.scatter(Y_target_test, Y_pred_test, s=30, c='green', edgecolor='black', linewidth=1, alpha=0.75, \n",
    "            label='Test set')\n",
    "\n",
    "plt.scatter(Y_train_new, Y_pred_train, s=30, c='red', edgecolor='black', linewidth=1, alpha=0.75, label='Train set')\n",
    "\n",
    "plt.plot([np.min(Y_target_test),np.max(Y_target_test)], \n",
    "         [np.min(Y_target_test),np.max(Y_target_test)], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Performance of ML model for \\ntrain and test set', fontdict=fontdict_t, color='black')\n",
    "\n",
    "plt.xlabel('GCMC simulated $N_{C_{3}H_{6}}$', fontdict=fontdict_x)\n",
    "plt.ylabel('ML Predicted $N_{C_{3}H_{6}}$', fontdict=fontdict_y)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#3.0, 1.3, 2.7, 1.1, 2.5, 0.9, 2.41, 0.7\n",
    "\n",
    "plt.text(3.0, 1.3, str('Train     Test'), weight='bold', horizontalalignment='left', size='medium', \n",
    "         color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.7, 1.1, str('$\\mathregular{R^2:}$') + '{:.3f}'.format(r2_score(Y_train_new, Y_pred_train)) + \n",
    "         str('   ') + '{:.3f}'.format(r2_score(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.5, 0.9, str('$\\mathregular{MAE: }$') + '{:.3f}'.format(mean_absolute_error(Y_train_new, Y_pred_train)) +\n",
    "         str('   ') + '{:.3f}'.format(mean_absolute_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.text(2.41, 0.7, str('$\\mathregular{RMSE: }$') + '{:.3f}'.format(mean_squared_error(Y_train_new, Y_pred_train)) +\n",
    "         str('   ') + '{:.3f}'.format(mean_squared_error(Y_target_test, Y_pred_test)), weight='bold', \n",
    "         horizontalalignment='left', size='medium', color='black', fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_propylene_uptake = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3748c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del etr\n",
    "#del svr\n",
    "del param_grid\n",
    "del grid_search\n",
    "del GridSearchCV\n",
    "#del ticks\n",
    "#del mean_val\n",
    "del mean_train\n",
    "#del std_val\n",
    "#del std_train\n",
    "del Y_pred_val\n",
    "del Y_pred_train\n",
    "del localimportance\n",
    "del explainer\n",
    "del index\n",
    "del feature_importance\n",
    "del df_cv_result_propylene_uptake\n",
    "del shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f30a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "295.844px",
    "left": "612.667px",
    "right": "20px",
    "top": "84px",
    "width": "544px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
